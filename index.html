
<!DOCTYPE html>
<html>
<head>
    <title>Home</title>
    <link rel="stylesheet" href="style.css" />
    <!-- <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=PT+Sans" /> -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        tag {
            width: 0.5em;
            height:0.809em;
            display: inline-block;
            margin: 0em 0em 0em 0.25em;
        }
        .ml {
            background-color: blue;
        }
        .nlp {
            background-color: green;
        }
        .cv {
            background-color: pink;
        }
        .math {
            background-color: yellow;
        }
    </style>
</head>
<body>

<table style="border:0px;">
    <tr><td style="width:215px;vertical-align:top;padding-right:5px;">
        <h1>Kolya Malkin's homepage</h1>
        <p>
            <img src="images/portrait2.jpg" style="width:100%;" alt="Portrait of a person (Nikolay Malkin in Montreal in 2025) with medium-length wavy brown hair, a green turtleneck, earrings, and glasses smiling against a white background." />
            <i>On a cold day in Montr&eacute;al, 2025.</i>
        </p>
        <h2 id="about">How to address / refer to me</h2>
        <h3>Name</h3>
        <p>
            &ldquo;Nikolay Malkin&rdquo; for official purposes (at least for now). If we are working together or on friendly terms, please call me &ldquo;Kolya&rdquo; &ndash; a standard short form in Russian for &ldquo;Nikolay&rdquo;.
        </p>
        <h3>Pronouns</h3>
        <p>
            <i>they&ge;she&gt;he&ge;0</i>
            <details>
                <summary>For the curious</summary>
                <p>
                    I prefer <i>they</i> or <i>she</i> in English. It is incorrect to refer to me with <i>he</i> or other male-gendered language &ndash; such as by opening emails with &ldquo;Dear Sir&rdquo; &ndash; or to edit <i>sua sponte</i> my gender in biographies.
                </p>
                <p>
                    If singular <i>they</i> feels unfamiliar, just use <i>she</i>.
                    If using my official-purpose name (Nikolay / Kolya) with <i>she</i> feels odd, just use <i>they</i>.
                    If both feel odd, please pick the one that is less so for you.
                </p>
                <p>
                    If this is confusing, just ask.
                </p>
            </details>
        </p>
        <h2 id="contact">Contact</h2>
        <p>
            Communication is accepted in English, French, Russian, and occasionally other languages.
        </p>
        <h3>Address</h3>
        <p>
            Informatics Forum 2.27<br/>10 Crichton Street<br/>Edinburgh EH8 9AB<br/>Scotland, UK
        </p>
        <h3>Email</h3>
        <p> 
            <a href="mailto:nmalkin@ed.ac.uk">UoE</a> (preferred)<br/><a href="mailto:nikolay.malkin@mila.quebec">Mila</a> (old)<br/><a href="mailto:kolya_malkin@hotmail.com">backup</a>
        </p>
        <h3>Other profiles</h3>
        <p>
            <a href="https://github.com/malkin1729">GitHub</a>
            <br/>
            <a href="https://x.com/felineautomaton">X / Twitter</a>
            <br/>
            <a href="https://bsky.app/profile/felineautomaton.bsky.social">Bluesky</a>
            <br />
            <a href="https://scholar.google.com/citations?user=S_Nn-XYAAAAJ">Google Scholar</a>
            <br />
            <a href="https://www.semanticscholar.org/author/Nikolay-Malkin/2067020770">Semantic Scholar</a>
        </p>
        <h2 id="mhobook">Math(s) Out Loud</h2>
        <p>
            <img src="images/book_cover.jpeg" style="width:50%;" /><br />
            Available from the <a href="https://bookstore.ams.org/mcl-27/">American Mathematical Society</a> or <a href="https://www.amazon.com/dp/1470466937/">Amazon</a>.
        </p>
    </td>
    <td style="width:645px;vertical-align:top;;padding-right:5px;">
        <h1>Bayesian machine learning &bull; neurosymbolic AI &bull; ML for science and scientific reasoning</h1>
        <p>
            Since July 2024: Chancellor's Fellow @ <a href="https://www.ed.ac.uk">University of Edinburgh</a>, <a href="https://www.inf.ed.ac.uk">School of Informatics</a><br />
            Since April 2025: Programme Fellow @ <a href="https://cifar.ca">CIFAR</a>, <a href="https://cifar.ca/research-programs/learning-in-machines-brains/">Learning in Machines and Brains</a>
            <details>
                <summary>Expand for affiliation details</summary>
                Member of <a href="https://web.inf.ed.ac.uk/anc">Institute for Machine Learning</a> (formerly Institute for Adaptive and Neural Computation)<br />
                Affiliate member of <a href="https://web.inf.ed.ac.uk/ilcc">Institute for Language, Cognition and Computation</a>
                <br />
                Affiliate member of <a href="https://web.inf.ed.ac.uk/ipab">Institute for Action, Perception and Behaviour</a>
                <br />
                <a href="https://gail.ed.ac.uk/">Generative AI Laboratory</a> Fellow
                <br />
                <a href="https://ellis.eu">ELLIS</a> Member
            </details>
        </p>

        <h2 id="call">Call for students</h2>

        <p>
            I am always looking for motivated students to fill fully-funded PhD positions in the <a href="https://www.inf.ed.ac.uk">School of Informatics</a>, <a href="https://www.ed.ac.uk">University of Edinburgh</a>. Interested students should contact me to discuss research directions and the application processes for the various degree programmes that I can supervise. For international students, it is now too late to apply for entry in September 2026. Ideally, you should write before November 2026 to be considered for all available opportunities for entry in September 2027.
        </p>
        <details>
            <summary>Expand for details</summary>
            <p>
                Research topics are in the areas of Bayesian machine learning (including probabilistic reasoning in language, generative models, and neurosymbolic methods) and applications in the sciences. I am especially happy to work with students who have a strong background in mathematics and an interest in robust and interpretable AI. Please see my <a href="#research">research interests</a> and <a href="#pub">recent publications</a> for examples of the kind of work we might do together.
            </p>
            <p>
                Studentships include:
                <ul>
                    <li>
                        Funding for tuition and living expenses for the duration of the PhD, as well as discretionary travel and research funds and access to some of the <a href="https://www.epcc.ed.ac.uk/">most advanced computing facilities</a> in Britain.
                    </li>
                    <li>
                        A supportive and stimulating research environment in a <a href="https://www.ed.ac.uk/informatics/news-events/news/news-archive/news-archive/informatics-ref2021-results-global-reach-genuine-i">large, leading institution in computer science and AI</a> &ndash; with particular strengths in <a href="https://edinburghnlp.inf.ed.ac.uk/">NLP</a> and <a href="https://web.inf.ed.ac.uk/anc">probabilistic machine learning</a>, as well as theoretical CS, robotics, and other areas &ndash; and a <a href="https://www.ed.ac.uk/informatics/news-events/news/2023/school-of-informatics-to-lead-new-genai-lab">major new investment in generative AI</a>.
                    </li>
                    <li>
                        The opportunity to collaborate with researchers at other world-class institutions.
                    </li>
                    <li>
                        A chance to explore one of the world's most beautiful, historic, and <a href="https://www.edinburgh.gov.uk/news/article/13711/living-longer-and-living-well-in-the-best-city-in-the-world-">livable</a> cities.
                    </li>
                </ul>
            </p>
            <p>
                The typical length of a PhD in the UK is 3-3.5 years. All students have at least one secondary supervisor &ndash; please let me know if you have a specific person or lab in mind &ndash; and there are many opportunities for collaboration.
            </p>
        </details>
        <p>
            (I regret that I cannot engage in individual discussions with everyone who contacts me, despite my best intentions. If I do not respond, please remind me. However, I am unlikely to answer messages that are hallucinated by a language model, which account for an increasing number. <b>No need for polished essays! I just want to know about you, your interests, and how you think we might work together.</b>)
        </p>
        <h3>On diversity and inclusion</h3>
        <p>
            Diverse perspectives shape impactful research. If you have an unusual education history, come from an ethnic/cultural minority, or identify as a woman, non-binary person, or queer individual, and you are interested in working with me, I especially encourage you to apply and to mention this if you feel comfortable doing so.
        </p>
        <p>
            I am committed to maintaining an inclusive environment for everyone I interact with and to considering ethics and fairness in both collaboration choices and research topics. I participate in and contribute to the activities of <a href="https://www.wiml.org/">Women in Machine Learning</a> and <a href="https://www.queerinai.com/">Queer in AI</a>, groups that take direct action to reduce barriers to participation in our field.
        </p>

        <h2 id="teaching">Teaching</h2>

        <p>
            In October-November 2024 I taught a mini-course on <b>diffusion probabilistic models</b>. Slides will be posted here eventually.
        </p>
        <p>
            In the spring of 2026 I will give a course on <b>Advanced Topics in Machine Learning</b>, newly designed with my colleagues <a href="https://vab.im/">Slava Borovitskiy</a> and <a href="https://homepages.inf.ed.ac.uk/rsarkar/">Rik Sarkar</a>. My track will focus on <b>deep generative modelling</b>, complementing those on geometric learning and optimisation.
        </p>

        <h2 id="prior">The prior distribution</h2>

        <p>
            Before moving to Edinburgh, I was a postdoc at <a href="https://mila.quebec">Mila &ndash; Qu&eacute;bec AI institute</a> and <a href="https://diro.umontreal.ca/">Department of Informatics and Operations Research</a>, <a href="https://umontreal.ca">Universit&eacute; de Montr&eacute;al</a>, where I was fortunate to work with Prof.&nbsp;<a href="https://yoshuabengio.org">Yoshua Bengio</a> and also to collaborate with Profs. <a href="https://mila.quebec/en/person/aaron-courville/">Aaron Courville</a>, <a href="https://gauthiergidel.github.io/">Gauthier Gidel</a>, and <a href="https://www.guillaumelajoie.com/">Guillaume Lajoie</a>, among others:
        </p>
        <details>
            <summary>Expand for collaborators and students</summary>
            <p>
                I have also been lucky to work with many fellow postdoctoctoral researchers (including <a href="https://kilianfatras.github.io/">Kilian Fatras</a>, <a href="https://alexhernandezgarcia.github.io/">Alex Hern&aacute;ndez-Garc&iacute;a</a>, <a href="https://pablo-lemos.github.io/">Pablo Lemos</a>, <a href="https://www.alextong.net/">Alex Tong</a>) and M.S./Ph.D. students and interns (including <a href="https://tristandeleu.github.io/">Tristan Deleu</a>, <a href="https://edwardjhu.com">Edward Hu</a>, <a href="https://mj10.github.io">Moksh Jain</a>, <a href="https://minsuukim.github.io/">Minsu Kim</a>, <a href="https://saleml.github.io/">Salem Lahlou</a>, <a href="https://jarridrb.github.io">Jarrid Rector-Brooks</a>, <a href="https://alexandravolokhova.github.io">Alexandra Volokhova</a>, <a href="https://zdhnarsil.github.io">Dinghuai Zhang</a>, among many others).
            </p>
        </details>
        <p>
            I was formally trained as a pure mathematician: at the <a href="http://www.math.washington.edu">University of Washington (Seattle)</a> (B.S., 2015) and <a href="https://math.yale.edu">Yale University</a> (M.S. and <a href="https://elischolar.library.yale.edu/gsas_dissertations/84/">Ph.D.</a>, 2021). In addition, I believe many individuals and societies could benefit from a dose of friendly mathematical education. Some organizations I have been involved in: <a href="http://www.math.washington.edu/~mathcircle">UW Math Circles</a> (Seattle), <a href="https://mathmaddicts.org">Math-M-Addicts</a> (New York City). I am also a coauthor of this <a href="#mhobook">collection of problems and puzzles</a>.
        </p>
        <h2 id="bio">Short bio in third person</h2>
        <p>
            <i>
                (Feel free to use if needed for talks and similar.)
            </i>
        </p>
        <p>
            Nikolay Malkin is a Chancellor's Fellow in Informatics at the University of Edinburgh and a fellow of CIFAR's Learning in Machines and Brains programme. 
            Their research focuses on algorithms for probabilistic inference and Bayesian machine learning, with applications in generative modelling, neurosymbolic AI, and machine reasoning. 
            Within machine learning, Nikolay's work explores modelling of Bayesian posteriors over high-dimensional and structured variables, induction and discovery of compositional structure in generative models, and neurosymbolic methods for uncertainty-aware reasoning in language and formal systems. 
            Their work has found applications in pure and applied sciences, including inverse imaging, remote sensing, discovery of novel biological and chemical structures, and, most recently, robot control. 
            Nikolay holds a PhD in mathematics from Yale University (2021) and was previously a postdoctoral researcher at Mila &ndash; Qu&eacute;bec AI Institute in Montr&eacute;al (2021 to 2024).
        </p>

        <h2 id="talks">Invited talks</h2>
        <p>
            I intend to <i>eventually</i> post slides for some of these. 
        </p>
        <h3>2025</h3>
        <item>
            <name>How to sample (and more) with dynamic measure transport</name>
            <journal>Constructor University, Bayes Group</journal>
            <authors>Bremen, November 2025</authors>
        </item>
        <item>
            <name>Learning to construct for generative modelling and Bayesian inference</name>
            <journal>Constructor University</journal>
            <authors>Bremen, November 2025</authors>
        </item>
        <item>
            <name>How to sample (and more) with dynamic measure transport</name>
            <journal>Technische Universit&auml;t M&uuml;nchen</journal>
            <authors>Munich, November 2025</authors>
        </item>        
        <item>
            <name>Deep dynamic measure transport: from amortised sampling to Schrödinger bridges and beyond</name>
            <journal><a href="https://www.uni-heidelberg.de/einrichtungen/iwh/index_engl.html">Internationales Wissenschaftsforum</a>, <a href="https://ssp.math.uni-heidelberg.de/WS_GenMods_2025/Scientific_programme/sci.html">Generative models in science and machine learning</a> workshop</journal>
            <authors>Heidelberg, September 2025</authors>
        </item>
        <item>
            <name>Diffusion modelling for amortised inference</name>
            <journal><a href="https://www.newton.ac.uk">Isaac Newton Institute for Mathematical Sciences</a>, <a href="https://www.newton.ac.uk/event/rclw03/">Accelerating statistical inference and experimental design with machine learning</a> workshop</journal>
            <authors>Cambridge, June 2025</authors>
        </item>
        <item>
            <name>Diffusion model tutorial</name>
            <journal><a href="https://www.newton.ac.uk">Isaac Newton Institute for Mathematical Sciences</a>, <a href="https://www.newton.ac.uk/event/rclw03/">Accelerating statistical inference and experimental design with machine learning</a> workshop</journal>
            <authors>Cambridge, June 2025</authors>
        </item>
        <item>
            <name>Stochastic control for black-box inference: Insights from deep reinforcement learning</name>
            <journal><a href="https://bayescomp2025.sg">BayesComp 2025</a></journal>
            <authors>Singapore, June 2025</authors>
        </item>
        <item>
            <name>Amortised inference meets LLMs: Algorithms and implications for faithful knowledge extraction</name>
            <journal><a href="https://simons.berkeley.edu/homepage">Simons Institute for the Theory of Computing</a>, <a href="https://simons.berkeley.edu/workshops/safety-guaranteed-llms">Safety-Guaranteed LLMs</a> workshop</journal>
            <authors>Berkeley, April 2025</authors>
        </item>
        <item>
            <name>The latest in generative AI research</name>
            <journal><a href="https://efi.ed.ac.uk">Edinburgh Futures Institute</a> / <a href="https://www.morganstanley.com/about-us/inclusive-sustainable-ventures">Morgan Stanley Inclusive Ventures Lab</a></journal>
            <authors>Edinburgh, February 2025</authors>
        </item>
        <item>
            <name>Diffusion models without data: Towards plans and representations from stochastic dynamics</name>
            <journal><a href="https://ethz.ch/">ETH Z&uuml;rich</a>, <a href="https://ai.ethz.ch">AI Center</a></journal>
            <authors>Z&uuml;rich, February 2025</authors>
        </item>
        <h3>2024</h3>
        <item>
            <name>Plans and symbolic representations from stochastic dynamics</name>
            <journal><a href="https://cifar.ca">CIFAR</a>, <a href="https://cifar.ca/research-programs/learning-in-machines-brains/">Learning in Machines and Brains</a> program meeting</journal>
            <authors>Toronto, November 2024</authors>
        </item>
        <item>
            <name>Diffusion models without data</name>
            <journal><a href="https://kth.se">KTH Royal Institute of Technology</a>, <a href="https://www.digitalfutures.kth.se">Digital Futures</a></journal>
            <authors>Stockholm, October 2024</authors>
        </item>
        <item>
            <name>Amortising intractable inference with diffusion models and off-policy RL</name>
            <journal><a href="https://hse.ru">Higher School of Economics</a>, <a href="https://cs.hse.ru/en/iai/hdilab/">High-Dimensional Inference Lab</a></journal>
            <authors>Moscow / virtual, August 2024</authors>
        </item>
        <h3>2023</h3>
        <item>
            <name>Developments in amortized posterior inference with foundation models</name>
            <journal><a href="https://cifar.ca">CIFAR</a>, <a href="https://cifar.ca/research-programs/learning-in-machines-brains/">Learning in Machines and Brains</a> program meeting</journal>
            <authors>New Orleans, December 2023</authors>
        </item>
        <item>
            <name>Two variational perspectives on diffusion models</name>
            <journal>Google DeepMind</journal>
            <authors>London / virtual, December 2023</authors>
        </item>
        <item>
            <name>Bayesian neurosymbolic AI for reasoning and scientific discovery</name>
            <journal>University of Edinburgh, School of Informatics</journal>
            <authors>Edinburgh, November 2023</authors>
        </item>
        <item>
            <name>Generative flow networks for inference over structured objects</name>
            <journal>Stony Brook University, Computer Science colloquium</journal>
            <authors>Stony Brook, March 2023</authors>
        </item>
        <item>
            <name>Probabilistic inference for reasoning with large language models</name>
            <journal>Columbia University, NLP seminar</journal>
            <authors>New York, March 2023</authors>
        </item>
        <item>
            <name>Probabilistic inference for reasoning with large language models</name>
            <journal>Microsoft Research</journal>
            <authors>Montr&eacute;al / virtual, February 2023</authors>
        </item>
        <item>
            <name>Generative flow networks: Theory, applications, and connections</name>
            <journal>Google Research, Bayesflow seminar</journal>
            <authors>New York / virtual, January 2023</authors>
        </item>
        <h3>2022</h3>
        <item>
            <name>Coherence boosting: When your pretrained language model is not paying enough attention</name>
            <journal>ACL 2022</journal>
            <authors>Dublin, May 2022</authors>
        </item>
        <h3>2021</h3>
        <item>
            <name>Studying word order through iterative shuffling</name>
            <journal>EMNLP 2021</journal>
            <authors>Punta Cana, November 2021</authors>
        </item>
        <item>
            <name>GPT Perdetry Test: Generating new meanings for new words</name>
            <journal>NAACL 2021</journal>
            <authors>virtual, June 2021</authors>
        </item>
        <item>
            <name>New approaches to computer vision for land cover mapping and change detection</name>
            <journal>Microsoft Research</journal>
            <authors>Redmond / virtual, March 2021</authors>
        </item>
        <h3>2020</h3>
        <item>
            <name>Motivic fundamental groups of CM elliptic curves and geometry of Bianchi hyperbolic threefolds</name>
            <journal>Johns Hopkins University, Junior Number Theory Days</journal>
            <authors>Baltimore / virtual, December 2020</authors>
        </item>
        <item>
            <name>Land cover mapping with epitomes and clustering models</name>
            <journal>ML for Remote Sensing seminar</journal>
            <authors>virtual, August 2020</authors>
        </item>
        <item>
            <name>Human-machine collaboration for fast land cover mapping</name>
            <journal>ICLR 2020, Climate Change AI</journal>
            <authors>virtual, April 2020</authors>
        </item>
    </td>
    <td style="width:645px;vertical-align:top;">
        <h1 id="research">Research</h1>

        <p><i>
            The below classification is somewhat outdated and will be updated eventually. Recent papers should be more representative of current interests.
        </i></p>
        <p>
            I work on algorithms for <b>deep-learning-based reasoning</b> and their applications. I am specifically interested in the following subjects:
            <ul>
                <li><tag class="ml"></tag> <b>Machine learning for generative models</b>, in particular, induction of compositional structure in generative models and modeling of posteriors over high-dimensional explanatory variables (including with <b>continuous-time (diffusion) generative models</b>). Much of my recent work is on <a href="https://tinyurl.com/gflownet-tutorial">generative flow networks</a>, which are a path towards inference machines that build structured, uncertainty-aware explanations for observed data.</li>
                <li><tag class="nlp"></tag> Applications to <b>natural language processing</b> and <b>reasoning in language</b>: what large language models can do, what they cannot do, and how to overcome their limitations with improved inference procedures. I view <b>human-like symbolic, formal, and mathematical reasoning via Bayesian neurosymbolic methods</b> as a long-term aspiration for artificial intelligence.</li>
                <li><tag class="cv"></tag> Applications to <b>computer vision</b>: notably, below you can find my (older) work on AI for remote sensing (land cover mapping and change detection), which can be used for tracking land use patterns over time and monitoring the effects of climate change.</li>
            </ul>
        </p>

        <h2 id="students">Current students</h2>

        <p>I am fortunate to be primary or co-primary PhD supervisor to:
            <ul>
                <li><a href="https://mmacosha.github.io">Kirill Tamogashev</a>, expected to graduate in 2028</li>
                <li><a href="https://hyeok9855.github.io">Sanghyeok Choi</a>, expected to graduate in 2028</li>
                <li><a href="">Arran Carter</a> (with <a href="https://victorelvira.github.io/">V&iacute;ctor Elvira</a>, School of Mathematics), expected to graduate in 2029</li>
            </ul>
            and external co-supervisor to:
            <ul>
                <li><a href="https://hyperpotatoneo.github.io">Siddarth Venkatraman</a> (with <a href="https://neo-x.github.io">Glen Berseth</a>, Universit&eacute; de Montr&eacute;al), expected to graduate in 2027</li>
            </ul>
            and secondary supervisor to:
            <ul>
                <li><a href="https://alexgurung.me">Alex Gurung</a> (with <a href="https://homepages.inf.ed.ac.uk/mlap/">Mirella Lapata</a>), expected to graduate in 2026</li>
                <li><a href="https://lenazellinger.github.io">Lena Zellinger</a> (with <a href="http://nolovedeeplearning.com">Antonio Vergari</a>), expected to graduate in 2027</li>
                <li><a href="https://rajit906.github.io">Rajit Rajpal</a> (with <a href="https://webhomes.maths.ed.ac.uk/~bleimkuh/">Ben Leimkuhler</a>, School of Mathematics), expected to graduate in 2027</li>
                <li><a href="">Yuanhao Jiang</a> (with <a href="https://webhomes.maths.ed.ac.uk/~bleimkuh/">Ben Leimkuhler</a>, School of Mathematics), expected to graduate in 2029</li>
            </ul>
        </p>
        <p>
            I have worked with other students in Edinburgh in various capacities, including 
            <a href="https://www.branchini.fun/">Nicola Branchini</a>, 
            <a href="https://honggiwon.github.io/">Giwon Hong</a>, 
            <a href="https://ben-sanati.github.io/">Ben Sanati</a>, 
            <a href="https://ansocho.github.io/">Andreas Sochopoulos</a>.
        </p>

        <h2 id="pub">Publications and preprints </h2>

        <h3>In submission / preparation</h3>
        <item>
            <name><a href="">How to approximate inference with subtractive mixture models</a><tag class="ml"></tag></name>
            <authors>Lena Zellinger, Nicola Branchini, Lennert De Smet, V&iacute;ctor Elvira, <me>Nikolay Malkin</me>, Antonio Vergari</authors>
            <journal>preprint TBA</journal>
        </item>
        <item>
            <name><a href="">Bayesian symbolic regression with entropic reinforcement learning</a><tag class="ml"></tag></name>
            <authors>Oussama Boussif, Mohammed Mahfoud, Younesse Kaddar, Moksh Jain, Sida Li, Damiano Fornasiere, Xiaoyin Chen, Yoshua Bengio, <me>Nikolay Malkin</me></authors>
            <journal>preprint TBA</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2512.21852">A comedy of estimators: On KL regularization in RL training of LLMs</a><tag class="nlp"></tag></name>
            <authors>Vedant Shah, Johan Obando-Ceron, Vineet Jain, Brian Bartoldson, Bhavya Kailkhura, Sarthak Mittal, Glen Berseth, Pablo Samuel Castro, Yoshua Bengio, <me>Nikolay Malkin</me>, Moksh Jain, Siddarth Venkatraman, Aaron Courville</authors>
            <journal>preprint</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2512.02240">Lightweight latent reasoning for narrative tasks</a><tag class="nlp"></tag></name>
            <authors>Alex Gurung, <me>Nikolay Malkin</me>, Mirella Lapata</authors>
            <journal>preprint</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2511.19594">Pixellated posterior sampling of point spread functions in astronomical images</a><tag class="ml"></tag></name>
            <authors>Connor Stone, Ronan Legin, Alexandre Adam, <me>Nikolay Malkin</me>, Gabriel Missael Barco, Laurence Perreault-Levasseur, Yashar Hezaveh</authors>
            <journal>preprint</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2511.19595">Mind the information gap: Unveiling detailed morphologies of z&Tilde;0.5&ndash;1.0 galaxies with SLACS strong lenses and data-driven analysis</a><tag class="ml"></tag></name>
            <authors>Ronan Legin, Connor Stone, Alexandre Adam, Gabriel Missael Barco, Adam Coogan, <me>Nikolay Malkin</me>, Laurence Perreault-Levasseur, Yashar Hezaveh</authors>
            <journal>preprint</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2511.04666">Forgetting is everywhere</a><tag class="ml"></tag></name>
            <authors>Ben Sanati, Thomas Lee, Trevor McInroe, Aidan Scannell, <me>Nikolay Malkin</me>, David Abel, Amos Storkey</authors>
            <journal>preprint</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2510.11711">Reinforced sequential Monte Carlo for amortised sampling</a><tag class="ml"></tag></name>
            <authors>Sanghyeok Choi, Sarthak Mittal, V&iacute;ctor Elvira, Jinkyoo Park, <me>Nikolay Malkin</me></authors>
            <journal>preprint</journal>
            <journal>version in ICML 2025 &ldquo;Generative AI and Biology&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2510.01159">Multi-marginal flow matching with adversarially learnt interpolants</a><tag class="ml"></tag></name>
            <authors>Oskar Kviman, Kirill Tamogashev, Nicola Branchini, V&iacute;ctor Elvira, Jens Lagergren, <me>Nikolay Malkin</me></authors>
            <journal>preprint</journal>
            <journal>version in NeurIPS 2025 &ldquo;Frontiers in Probabilistic Inference&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2509.26626">Recursive self-aggregation unlocks deep thinking in large language models</a><tag class="nlp"></tag></name>
            <authors>Siddarth Venkatraman&ast;, Vineet Jain&ast;, Sarthak Mittal&ast;, Vedant Shah, Johan Obando-Ceron, Yoshua Bengio, Brian Bartoldson, Bhavya Kailkhura, Guillaume Lajoie, Glen Berseth, <me>Nikolay Malkin</me>, Moksh Jain</authors>
            <journal>preprint</journal>
            <journal>version in NeurIPS 2025 &ldquo;Foundations of Reasoning in Language Models&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2509.26364">Data-to-energy stochastic dynamics</a><tag class="ml"></tag></name>
            <authors>Kirill Tamogashev, <me>Nikolay Malkin</me></authors>
            <journal>preprint</journal>
            <journal>version in NeurIPS 2025 &ldquo;Frontiers in Probabilistic Inference&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2506.17007">Robust reinforcement learning for discrete compositional generation via general soft operators</a><tag class="ml"></tag></name>
            <authors>Marco Jiralerspong, Esther Derman, Danilo Vucetic, <me>Nikolay Malkin</me>, Bilun Sun, Tianyu Zhang, Pierre-Luc Bacon, Gauthier Gidel</authors>
            <journal>preprint</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2506.01541">Adaptive destruction processes for diffusion samplers</a><tag class="ml"></tag></name>
            <authors>Timofei Gritsaev, Nikita Morozov, Kirill Tamogashev, Daniil Tiapkin, Sergey Samsonov, Alexey Naumov, Dmitry Vetrov, <me>Nikolay Malkin</me></authors>
            <journal>preprint</journal>
            <journal>version in NeurIPS 2025 &ldquo;Frontiers in Probabilistic Inference&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2506.00136">On designing diffusion autoencoders for efficient generation and representation learning</a><tag class="ml"></tag></name>
            <authors>Magdalena Proszewska, <me>Nikolay Malkin</me>, N. Siddharth</authors>
            <journal>preprint</journal>
            <journal>version in CVPR 2025 &ldquo;Generative Models for Computer Vision&rdquo; workshop</journal>
        </item>

        <h3>2026</h3>

        <h4>Accepted / published</h4>
        <item>
            <name><a href="https://arxiv.org/abs/2501.06148">From discrete-time policies to continuous-time diffusion samplers: Asymptotic equivalences and faster training</a><tag class="ml"></tag></name>
            <authors>Julius Berner&ast;, Lorenz Richter&ast;, Marcin Sendera&ast;, Jarrid Rector-Brooks, <me>Nikolay Malkin</me></authors>
            <journal>TMLR</journal>
        </item>

        <h3>2025</h3>

        <h4>Accepted / published</h4>
        <item>
            <name><a href="https://arxiv.org/abs/2505.01179">Fast flow-based visuomotor policies via conditional optimal transport couplings</a><tag class="ml"></tag></name>
            <authors>Andreas Sochopoulos, <me>Nikolay Malkin</me>, Nikolaos Tsagkas, Jo&atilde;o Moura, Michael Gienger, Sethu Vijayakumar</authors>
            <journal>CoRL 2025</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2411.02830">Mixtures of in-context learners</a><tag class="nlp"></tag></name>
            <authors>Giwon Hong, Emile Van Krieken, <me>Nikolay Malkin</me>, Edoardo Ponti, Pasquale Minervini</authors>
            <journal>ACL 2025</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2408.05284">Can a Bayesian oracle prevent harm from an agent?</a><tag class="ml"></tag></name>
            <authors>Yoshua Bengio&ast;, Michael K. Cohen&ast;, <me>Nikolay Malkin</me>&ast;, Matt MacDermott, Damiano Fornasiere, Pietro Greiner, Younesse Kaddar</authors>
            <journal>UAI 2025</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2502.06999">Outsourced diffusion sampling: Efficient posterior inference in latent spaces of generative models</a><tag class="ml"></tag></name>
            <authors>Siddarth Venkatraman&ast;, Mohsin Hasan&ast;, Minsu Kim, Luca Scimeca, Marcin Sendera, Yoshua Bengio, Glen Berseth, <me>Nikolay Malkin</me></authors>
            <journal>ICML 2025</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2410.15184">Action abstractions for amortized sampling</a><tag class="ml"></tag></name>
            <authors>Oussama Boussif, L&eacute;na N&eacute;hale Ezzine, Joseph Viviano, Micha&lstrok; Koziarski, Moksh Jain, <me>Nikolay Malkin</me>, Emmanuel Bengio, Rim Assouel, Yoshua Bengio</authors>
            <journal>ICLR 2025</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2410.01432">Adaptive teachers for amortized samplers</a><tag class="ml"></tag></name>
            <authors>Minsu Kim&ast;, Sanghyeok Choi&ast;, Taeyoung Yun, Emmanuel Bengio, Leo Feng, Jarrid Rector-Brooks, Sungsoo Ahn, Jinkyoo Park, <me>Nikolay Malkin</me>, Yoshua Bengio</authors>
            <journal>ICLR 2025</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2405.18540">Learning diverse attacks on large language models for robust red-teaming and safety tuning</a><tag class="nlp"></tag></name>
            <authors>Seanie Lee, Minsu Kim, Lynn Cherif, David Dobre, Juho Lee, Sung Ju Hwang, Kenji Kawaguchi, Gauthier Gidel, Yoshua Bengio, <me>Nikolay Malkin</me>, Moksh Jain</authors>
            <journal>ICLR 2025</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2402.04355">PQMass: Probabilistic assessment of the quality of generative models using probability mass estimation</a><tag class="ml"></tag></name>
            <authors>Pablo Lemos, Sammy Nasser Sharief, <me>Nikolay Malkin</me>, Laurence Perreault-Levasseur, Yashar Hezaveh</authors>
            <journal>ICLR 2025</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2503.06985">Learning decision trees as amortized structure inference</a><tag class="ml"></tag></name>
            <authors>Mohammed Mahfoud, Ghait Boukachab, Micha&lstrok; Koziarski, Alex Hern&aacute;ndez-Garc&iacute;a, Stefan Bauer, Yoshua Bengio, <me>Nikolay Malkin</me></authors>
            <journal>ICLR 2025 &ldquo;Frontiers in Probabilistic Inference&rdquo; workshop</journal>
        </item>
        <h4>Preprints / notes</h4>
        <item>
            <name><a href="https://arxiv.org/abs/2502.11617">In-context parametric inference: Point or distribution estimators?</a><tag class="ml"></tag></name>
            <authors>Sarthak Mittal, Yoshua Bengio, <me>Nikolay Malkin</me>, Guillaume Lajoie</authors>
            <journal>preprint</journal>
        </item>
            
        <h3>2024</h3>

        <h4>Accepted / published</h4>

        <item>
            <name><a href="https://arxiv.org/abs/2405.20971">Amortizing intractable inference in diffusion models for vision, language, and control</a><tag class="ml"></tag></name>
            <authors>Siddarth Venkatraman&ast;, Moksh Jain&ast;, Luca Scimeca&ast;, Minsu Kim&ast;, Marcin Sendera&ast;, Mohsin Hasan, Luke Rowe, Sarthak Mittal, Pablo Lemos, Emmanuel Bengio, Alexandre Adam, Jarrid Rector-Brooks, Yoshua Bengio, Glen Berseth, <me>Nikolay Malkin</me></authors>
            <journal>NeurIPS 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2402.05098">Improved off-policy training of diffusion samplers</a><tag class="ml"></tag></name>
            <authors>Marcin Sendera, Minsu Kim, Sarthak Mittal, Pablo Lemos, Luca Scimeca, Jarrid Rector-Brooks, Alexandre Adam, Yoshua Bengio, <me>Nikolay Malkin</me></authors>
            <journal>NeurIPS 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2410.13224">Proof Flow: Preliminary study on generative flow network language model tuning for formal reasoning</a><tag class="nlp"></tag></name>
            <authors>Matthew Ho, Vincent Zhu, Xiaoyin Chen, Moksh Jain, <me>Nikolay Malkin</me>, Edwin Zhang</authors>
            <journal>NeurIPS 2024 &ldquo;System-2 Reasoning at Scale&rdquo; workshop</journal>
        </item>
        <item>
            <name>Amortizing intractable inference in diffusion models for Bayesian inverse problems</a><tag class="ml"></tag> [extension of <a href="https://arxiv.org/abs/2405.20971">conference paper</a>]</name>
            <authors>Siddarth Venkatraman, Moksh Jain, Luca Scimeca, Minsu Kim, Marcin Sendera, Mohsin Hasan, Luke Rowe, Sarthak Mittal, Pablo Lemos, Emmanuel Bengio, Alexandre Adam, Jarrid Rector-Brooks, Yashar Hezaveh, Laurence Perreault-Levasseur, Yoshua Bengio, Glen Berseth, <me>Nikolay Malkin</me></authors>
            <journal>NeurIPS 2024 &ldquo;Machine Learning and the Physical Sciences&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://pubs.aip.org/aip/jcp/article-pdf/doi/10.1063/5.0226408/20201406/144106_1_5.0226408.pdf">Path-filtering in path-integral simulations of open quantum systems using GFlowNets</a><tag class="ml"></tag></name>
            <authors>Jeremy Lackman-Mincoff, Moksh Jain, <me>Nikolay Malkin</me>, Yoshua Bengio, Lena Simine</authors>
            <journal>Journal of Chemical Physics 161(14), 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2402.06457">V-STaR: Training verifiers for self-taught reasoners</a><tag class="nlp"></tag></name>
            <authors>Arian Hosseini, Xingdi Yuan, <me>Nikolay Malkin</me>, Aaron Courville, Alessandro Sordoni, Rishabh Agarwal</authors>
            <journal>COLM 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2403.04571">Machine learning and information theory concepts towards an AI Mathematician</a><tag class="ml"></tag><tag class="math"></tag></name>
            <authors>Yoshua Bengio, <me>Nikolay Malkin</me></authors>
            <journal>Bulletin of the American Mathematical Society, 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2402.06121">Iterated denoising energy matching for sampling from Boltzmann densities</a><tag class="ml"></tag></name>
            <authors>Tara Akhound-Sadegh&ast;, Jarrid Rector-Brooks&ast;, Joey Bose&ast;, Sarthak Mittal, Pablo Lemos, Cheng-Hao Liu, Marcin Sendera, Siamak Ravanbakhsh, Gauthier Gidel, Yoshua Bengio, <me>Nikolay Malkin</me>, Alexander Tong</authors>
            <journal>ICML 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2312.03911">Improving gradient-guided nested sampling for posterior inference</a><tag class="ml"></tag></name>
            <authors>Pablo Lemos, <me>Nikolay Malkin</me>, Will Handley, Yoshua Bengio, Yashar Hezaveh, Laurence Perreault-Levasseur</authors>
            <journal>ICML 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2402.10309">Discrete probabilistic inference as control in multi-path environments</a><tag class="ml"></tag></name>
            <authors>Tristan Deleu, Padideh Nouri, <me>Nikolay Malkin</me>, Doina Precup, Yoshua Bengio</authors>
            <journal>UAI 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2310.04363">Amortizing intractable inference in large language models</a><tag class="nlp"></tag></name>
            <authors>Edward Hu&ast;, Moksh Jain&ast;, Eric Elmoznino, Younesse Kaddar, Guillaume Lajoie, Yoshua Bengio, <me>Nikolay Malkin</me></authors>
            <journal>ICLR 2024; best paper honourable mention</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2310.02423">Delta-AI: Local objectives for amortized inference in sparse graphical models</a><tag class="ml"></tag></name>
            <authors>Jean-Pierre Falet&ast;, Hae-Beom Lee&ast;, <me>Nikolay Malkin</me>&ast;, Chen Sun, Dragos Secrieru, Dinghuai Zhang, Guillaume Lajoie, Yoshua Bengio</authors>
            <journal>ICLR 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2310.02779">Expected flow networks in stochastic environments and two-player zero-sum games</a><tag class="ml"></tag></name>
            <authors>Marco Jiralerspong&ast;, Bilun Sun&ast;, Danilo Vucetic&ast;, Tianyu Zhang, Yoshua Bengio, Gauthier Gidel, <me>Nikolay Malkin</me></authors>
            <journal>ICLR 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2310.08774">PhyloGFN: Phylogenetic inference with GFlowNets</a><tag class="ml"></tag></name>
            <authors>Ming Yang Zhou, Zichao Yan, Elliot Layne, <me>Nikolay Malkin</me>, Dinghuai Zhang, Moksh Jain, Mathieu Blanchette, Yoshua Bengio</authors>
            <journal>ICLR 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2307.03672">Simulation-free Schr&ouml;dinger bridges via score and flow matching</a><tag class="ml"></tag></name>  
            <authors>Alexander Tong&ast;, <me>Nikolay Malkin</me>&ast;, Kilian Fatras&ast;, Lazar Atanackovic, Yanlei Zhang, Guillaume Huguet, Hananeh Aliee, Guy Wolf, Yoshua Bengio</authors>
            <journal>AISTATS 2024</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2302.00482">Improving and generalizing flow-based generative models with minibatch optimal transport</a><tag class="ml"></tag></name>  
            <authors>Alexander Tong&ast;, Kilian Fatras&ast;, <me>Nikolay Malkin</me>&ast;, Guillaume Huguet, Yanlei Zhang, Jarrid Rector-Brooks, Guy Wolf, Yoshua Bengio</authors>
            <journal>TMLR</journal>
        </item>
        <h4>Preprints / notes</h4>
        <item>
            <name><a href="https://arxiv.org/abs/2407.03105">On generalization for generative flow networks</a><tag class="ml"></tag></name>
            <authors>Anas Krichel, <me>Nikolay Malkin</me>, Salem Lahlou, Yoshua Bengio</authors>
            <journal>preprint</journal>
        </item>

        <h3>2023</h3>

        <h4>Accepted / published</h4>

        <item>
            <name><a href="https://arxiv.org/abs/2305.19366">Joint Bayesian inference of graphical structure and parameters with a single generative flow network</a><tag class="ml"></tag></name>  
            <authors>Tristan Deleu, Mizu Nishikawa-Toomey, Jithendaraa Subramanian, <me>Nikolay Malkin</me>, Laurent Charlin, Yoshua Bengio</authors>
            <journal>NeurIPS 2023</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2305.17010">Let the flows tell: Solving graph combinatorial problems with GFlowNets</a><tag class="ml"></tag></name>  
            <authors>Dinghuai Zhang, Hanjun Dai, <me>Nikolay Malkin</me>, Aaron Courville, Yoshua Bengio, Ling Pan</authors>
            <journal>NeurIPS 2023</journal>
        </item>
        <item>
            <name><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4361565">Donor activity is associated with US legislators’ attention to political issues</a><tag class="nlp"></tag></name>
            <authors>Pranav Goel, <me>Nikolay Malkin</me>&ast;, SoRelle Gaynor&ast;, Nebojsa Jojic, Kristina Miler, Philip Resnik</authors>
            <journal>PLOS One, 2023</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2302.06576">GFlowNet-EM for learning compositional latent variable models</a><tag class="ml"></tag></name>  
            <authors>Edward Hu&ast;, <me>Nikolay Malkin</me>&ast;, Moksh Jain, Katie Everett, Alexandros Graikos, Yoshua Bengio</authors>
            <journal>ICML 2023</journal>
        </item>
        <item>
            <name><a href="http://arxiv.org/abs/2301.12594">A theory of continuous generative flow networks</a><tag class="ml"></tag></name>  
            <authors>Salem Lahlou, Tristan Deleu, Pablo Lemos, Dinghuai Zhang, Alexandra Volokhova, Alex Hern&aacute;ndez-Garc&iacute;a, L&eacute;na N&eacute;hale Ezzine, Yoshua Bengio, <me>Nikolay Malkin</me></authors>
            <journal>ICML 2023</journal>
        </item>
        <item>
            <name><a href="http://arxiv.org/abs/2209.12782">Learning GFlowNets from partial episodes for improved convergence and stability</a><tag class="ml"></tag></name>  
            <authors>Kanika Madan, Jarrid Rector-Brooks&ast;, Maksym Korablyov&ast;, Emmanuel Bengio, Moksh Jain, Andrei Nica, Tom Bosc, Yoshua Bengio, <me>Nikolay Malkin</me></authors>
            <journal>ICML 2023</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2302.01687">Better training of GFlowNets with local credit and incomplete trajectories</a><tag class="ml"></tag></name>
            <authors>Ling Pan, <me>Nikolay Malkin</me>, Dinghuai Zhang, Yoshua Bengio</authors>
            <journal>ICML 2023</journal>
        </item>
        <item>
            <name><a href="http://arxiv.org/abs/2210.12928">GFlowOut: Dropout with generative flow networks</a><tag class="ml"></tag></name>
            <authors>Dianbo Liu, Moksh Jain, Bonaventure Dossou, Qianli Shen, Salem Lahlou, Anirudh Goyal, <me>Nikolay Malkin</me>, Chris Emezue, Dinghuai Zhang, Nadhir Hassen, Xu Ji, Kenji Kawaguchi, Yoshua Bengio</authors>
            <journal>ICML 2023</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2306.17693">Thompson sampling for improved exploration in GFlowNets</a><tag class="ml"></tag></name>  
            <authors>Jarrid Rector-Brooks, Kanika Madan, Moksh Jain, Maksym Korablyov, Cheng-Hao Liu, Sarath Chandar, <me>Nikolay Malkin</me>, Yoshua Bengio</authors>
            <journal>ICML 2023 &ldquo;Structured Probabilistic Inference and Generative Modeling&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2306.15058">BatchGFN: Generative flow networks for batch active learning</a><tag class="ml"></tag></name>  
            <authors>Shreshth Malik, Salem Lahlou, Andrew Jesson, Moksh Jain, <me>Nikolay Malkin</me>, Tristan Deleu, Yoshua Bengio, Yarin Gal</authors>
            <journal>ICML 2023 &ldquo;Structured Probabilistic Inference and Generative Modeling&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://aclanthology.org/2023.acl-long.68/">Probabilistic reasoning over sets using large language models</a><tag class="nlp"></tag></name>  
            <authors>Batu Ozturkler, <me>Nikolay Malkin</me>, Zhen Wang, Nebojsa Jojic</authors>
            <journal>ACL 2023</journal>
        </item>
        <item>
            <name><a href="http://arxiv.org/abs/2210.00580">GFlowNets and variational inference</a><tag class="ml"></tag></name>  
            <authors><me>Nikolay Malkin</me>&ast;, Salem Lahlou&ast;, Tristan Deleu&ast;, Xu Ji, Edward Hu, Katie Everett, Dinghuai Zhang, Yoshua Bengio</authors>
            <journal>ICLR 2023</journal>
        </item>
        <h4>Preprints / notes</h4>
        <item>
            <name><a href="https://arxiv.org/abs/2209.02606">Unifying generative models with GFlowNets and beyond</a><tag class="ml"></tag></name>  
            <authors>Dinghuai Zhang, Ricky T. Q. Chen, <me>Nikolay Malkin</me>, Yoshua Bengio</authors>
            <journal>preprint</journal>
        </item>

        <h3>2022</h3>

        <h4>Accepted / published</h4>

        <item>
            <name><a href="https://arxiv.org/abs/2206.09012">Diffusion models as plug-ang-play priors</a><tag class="ml"></tag><tag class="cv"></tag></name>     
            <authors>Alexandros Graikos, <me>Nikolay Malkin</me>, Nebojsa Jojic, Dimitris Samaras</authors>
            <journal>NeurIPS 2022</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2201.13259">Trajectory balance: Improved credit assignment in GFlowNets</a><tag class="ml"></tag></name>     
            <authors><me>Nikolay Malkin</me>, Moksh Jain, Emmanuel Bengio, Chen Sun, Yoshua Bengio</authors>
            <journal>NeurIPS 2022</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2211.03812">Posterior samples of source galaxies in strong gravitational lenses with score-based priors</a><tag class="cv"></tag></name>  
            <authors>Alexandre Adam, Adam Coogan, <me>Nikolay Malkin</me>, Ronan Legin, Laurence Perreault Levasseur, Yashar Hezaveh, Yoshua Bengio</authors>
            <journal>NeurIPS 2022 &ldquo;Machine Learning for the Physical Sciences&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://openreview.net/forum?id=rfGNz_Uiqgq">Resolving label uncertainty with implicit posterior models</a><tag class="ml"></tag><tag class="cv"></tag></name>   
            <authors>Esther Rolf&ast;, <me>Nikolay Malkin</me>&ast;, Alexandros Graikos, Ana Jojic, Caleb Robinson, Nebojsa Jojic</authors>
            <!-- <journal>Uncertainty in Artificial Intelligence (<b>UAI</b>) 2022</journal> -->
            <journal>UAI 2022</journal>
        </item>
        <item>
            <name><a href="https://proceedings.mlr.press/v162/zhang22v.html">Generative flow networks for discrete probabilistic modeling</a><tag class="ml"></tag></name>    
            <authors>Dinghuai Zhang, <me>Nikolay Malkin</me>, Zhen Liu, Alexandra Volokhova, Aaron Courville, Yoshua Bengio</authors>
            <!-- <journal>International Conference on Machine Learning (<b>ICML</b>) 2022</journal> -->
            <journal>ICML 2022</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2209.02606v1">Unifying generative models with GFlowNets</a><tag class="ml"></tag></name>  
            <authors>Dinghuai Zhang, Ricky T. Q. Chen, <me>Nikolay Malkin</me>, Yoshua Bengio</authors>
            <journal>ICML 2022 &ldquo;Beyond Bayes: Paths Towards Universal Reasoning Systems&rdquo; workshop</journal>
        </item>
        <item>
            <name><a href="https://aclanthology.org/2022.acl-long.565/">Coherence boosting: When your pretrained language model is not paying enough attention</a><tag class="nlp"></tag></name>    
            <authors><me>Nikolay Malkin</me>, Zhen Wang, Nebojsa Jojic</authors>
            <!-- <journal>Association for Computational Linguistics (<b>ACL</b>) 2022</journal> -->
            <journal>ACL 2022</journal>
        </item>
        <item>
            <name><a href="https://ieeexplore.ieee.org/document/9690575">The outcome of the 2021 IEEE GRSS Data Fusion Contest - Track MSD: Multitemporal semantic change detection</a><tag class="cv"></tag></name>    
            <authors>Zhuohong Li, Fangxiao Lu, Hongyan Zhang, Lilin Tu, Jiayi Li, Xin Huang, Caleb Robinson, <me>Nikolay Malkin</me>, Nebojsa Jojic, Pedram Ghamisi, Ronny Hänsch, Naoto Yokoya</authors>
            <!-- <journal></journal>Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>JSTARS</b>)</journal> -->
            <journal>JSTARS vol.15</journal>
        </item>

        <h3>2021</h3> 

        <h4>Accepted / published</h4> 

        <item>
            <name><a href="https://aclanthology.org/2021.emnlp-main.809/">Studying word order through iterative shuffling</a><tag class="nlp"></tag></name>    
            <authors><me>Nikolay Malkin</me>, Sameera Lanka, Pranav Goel, Nebojsa Jojic</authors>
            <!-- <journal>Empirical Methods in Natural Language Processing (<b>EMNLP</b>) 2021</journal> -->
            <journal>EMNLP 2021</journal>
        </item>
        <item>
            <name><a href="https://aclanthology.org/2021.naacl-main.439/">GPT Perdetry Test: Generating new meanings for new words</a><tag class="nlp"></tag></name>    
            <authors><me>Nikolay Malkin</me>, Sameera Lanka, Pranav Goel, Sudha Rao, Nebojsa Jojic</authors>
            <!-- <journal>North American Chapter of the Association for Computational Linguistics (<b>NAACL</b>) 2021</journal> -->
            <journal>NAACL 2021</journal>
        </item>
        <item>
            <name><a href="https://ieeexplore.ieee.org/abstract/document/9554869">From local algorithms to global results: Human-machine collaboration for robust analysis of geographically diverse imagery</a><tag class="cv"></tag></name>    
            <authors>Nebojsa Jojic, <me>Nikolay Malkin</me>, Caleb Robinson, Anthony Ortiz</authors>
            <!-- <journal>International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>) 2021</journal> -->
            <journal>IGARSS 2021</journal>
        </item>
        <item>
            <name><a href="https://elischolar.library.yale.edu/gsas_dissertations/84/">On the Galois action on motivic fundamental groups of punctured elliptic and rational curves</a><tag class="math"></tag></name>    
            <authors><me>Nikolay Malkin</me>; thesis advisor A.B. Goncharov</authors>
            <journal>PhD thesis</journal>
        </item>
        <item>
            <name><a href="https://ieeexplore.ieee.org/document/9369830">Global land cover mapping with weak supervision: Outcome of the 2020 IEEE GRSS Data Fusion Contest</a><tag class="cv"></tag></name>     
            <authors>Caleb Robinson, <me>Nikolay Malkin</me>, Nebojsa Jojic, Huijun Chen, Rongjun Qin, Changlin Xiao, Michael Schmitt, Pedram Ghamisi, Ronny Hänsch, Naoto Yokoya</authors>
            <!-- <journal>Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>JSTARS</b>)</journal> -->
            <journal>JSTARS vol.14</journal>
        </item>

        <h4>Preprints / notes</h4>

        <item>
            <name><a href="https://arxiv.org/abs/2101.01154">High-resolution land cover change from low-resolution labels: Simple baselines for the 2021 IEEE GRSS Data Fusion Contest</a><tag class="cv"></tag></name>    
            <authors><me>Nikolay Malkin</me>, Caleb Robinson, Nebojsa Jojic</authors>
            <journal>preprint</journal>
        </item>  

        <h3>2020</h3>

        <h4>Accepted / published</h4>
        
        <item>
            <name><a href="https://ieeexplore.ieee.org/document/9547211">Weakly supervised semantic segmentation in the 2020 IEEE GRSS Data Fusion Contest</a><tag class="cv"></tag></name>    
            <authors>Caleb Robinson, <me>Nikolay Malkin</me>, Lucas Hu, Bistra Dilkina, Nebojsa Jojic</authors>
            <!-- <journal>International Geoscience and Remote Sensing Symposium (<b>IGARSS</b>) 2020; contest winner</journal> -->
            <journal>IGARSS 2020; contest winner</journal>
        </item>
        <item>
            <name><a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710528.pdf">Mining self-similarity: Label super-resolution with epitomic representations</a><tag class="ml"></tag><tag class="cv"></tag></name>   
            <authors><me>Nikolay Malkin</me>, Anthony Ortiz, Nebojsa Jojic</authors>
            <!-- <journal>European Conference on Computer Vision (<b>ECCV</b>) 2020</journal> -->
            <journal>ECCV 2020</journal>
        </item>
        <item>
            <name><a href="https://ojs.aaai.org/index.php/AAAI/article/view/5633">Human-machine collaboration for fast land cover mapping</a><tag class="cv"></tag></name>  
            <authors>Caleb Robinson, Anthony Ortiz, <me>Nikolay Malkin</me>, Blake Elias, Andi Peng, Dan Morris, Bistra Dilkina, Nebojsa Jojic</authors>
            <!-- <journal>Association for the Advancement of Artificial Intelligence (<b>AAAI</b>) 2020</journal> -->
            <journal>AAAI 2020</journal>
        </item>

        <h4>Preprints / notes</h4>

        <item>
            <name><a href="https://github.com/malkin1729/graph-cg/blob/master/graph-cg-paper.pdf">Learning intersecting representations of short random walks on graphs</a><tag class="ml"></tag></name>    
            <authors><me>Nikolay Malkin</me>, Nebojsa Jojic</authors>
            <journal>preprint</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2010.07238">Motivic fundamental groups of CM elliptic curves and geometry of Bianchi hyperbolic threefolds</a><tag class="math"></tag></name>    
            <authors><me>Nikolay Malkin</me></authors>
            <journal>preprint</journal>
        </item>
        <item>
            <name><a href="https://arxiv.org/abs/2003.06521">Shuffle relations for Hodge and motivic correlators</a><tag class="math"></tag></name>  
            <authors><me>Nikolay Malkin</me></authors>
            <journal>preprint</journal>
        </item>

        <h3>2019</h3>

        <h4>Accepted / published</h4>

        <item>
            <name><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Robinson_Large_Scale_High-Resolution_Land_Cover_Mapping_With_Multi-Resolution_Data_CVPR_2019_paper.pdf">Large scale high-resolution land cover mapping with multi-resolution data</a><tag class="cv"></tag></name>  
            <authors>Caleb Robinson, Le Hou, <me>Nikolay Malkin</me>, Rachel Soobitsky, Jacob Czawlytko, Bistra Dilkina, Nebojsa Jojic</authors>
            <!-- <journal>Computer Vision and Pattern Recognition (<b>CVPR</b>) 2019</journal> -->
            <journal>CVPR 2019</journal>
        </item>
        <item>
            <name><a href="https://openreview.net/forum?id=rkxwShA9Ym">Label super-resolution networks</a><tag class="cv"></tag></name>  
            <authors><me>Nikolay Malkin</me>, Caleb Robinson, Le Hou, Rachel Soobitsky, Jacob Czawlytko, Dimitris Samaras, Joel Saltz, Lucas Joppa, Nebojsa Jojic</authors>
            <!-- <journal>International Conference on Learning Representations (<b>ICLR</b>) 2019</journal> -->
            <journal>ICLR 2019</journal>
        </item>

        <h4>Preprints / notes</h4>

        <item>
            <name><a href="https://arxiv.org/abs/1904.04429">Label super-resolution with inter-instance loss</a><tag class="cv"></tag></name>  
            <authors>Maozheng Zhao, Le Hou, Han Le, Dimitris Samaras, Nebojsa Jojic, Danielle Fassler, Tahsin Kurc, Rajarsi Gupta, <me>Nikolay Malkin</me>, Shroyer Kenneth, Joel Saltz</authors>
            <journal>preprint</journal>
        </item>
    </td></tr>
</table>

</body>
</html>